{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.4.1-py2.py3-none-any.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 982 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting parsel>=1.5.0\n",
      "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting pyOpenSSL>=16.2.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zope.interface>=4.1.3\n",
      "  Downloading zope.interface-5.2.0.tar.gz (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting w3lib>=1.17.0\n",
      "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.1.16.tar.gz (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 699 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting cryptography>=2.0\n",
      "  Downloading cryptography-3.3.1.tar.gz (539 kB)\n",
      "\u001b[K     |████████████████████████████████| 539 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting service-identity>=16.0.0\n",
      "  Downloading service_identity-18.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting Twisted>=17.9.0\n",
      "  Downloading Twisted-20.3.0.tar.bz2 (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.5.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml>=3.5.0; platform_python_implementation == \"CPython\"\n",
      "  Downloading lxml-4.6.2.tar.gz (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 592 kB/s eta 0:00:01     |███████████████████████▊        | 2.4 MB 844 kB/s eta 0:00:01     |████████████████████████████    | 2.8 MB 844 kB/s eta 0:00:01     |██████████████████████████████▌ | 3.0 MB 844 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyDispatcher>=2.0.5\n",
      "  Downloading PyDispatcher-2.0.5.tar.gz (34 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.8/site-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from zope.interface>=4.1.3->scrapy) (50.3.2)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/site-packages (from cryptography>=2.0->scrapy) (1.14.2)\n",
      "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.8/site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: attrs>=16.0.0 in /usr/local/lib/python3.8/site-packages (from service-identity>=16.0.0->scrapy) (20.1.0)\n",
      "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.8/site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting incremental>=16.10.1\n",
      "  Using cached incremental-17.5.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Automat>=0.3.0\n",
      "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-20.0.1-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyHamcrest!=1.10.0,>=1.9.0\n",
      "  Downloading PyHamcrest-2.0.2-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.20)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.8/site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (2.10)\n",
      "Building wheels for collected packages: zope.interface, protego, cryptography, Twisted, lxml, PyDispatcher\n",
      "  Building wheel for zope.interface (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zope.interface: filename=zope.interface-5.2.0-cp38-cp38-macosx_11_0_x86_64.whl size=194380 sha256=52e7b9ef8664085357753df6fc0e9b92f8a291be5669b419a80c34a4cd1987c4\n",
      "  Stored in directory: /Users/Gustavo-NB/Library/Caches/pip/wheels/dc/e0/2f/e9e399d32e556c9033e3ba387a1c1b54e1464bd0316729cb92\n",
      "  Building wheel for protego (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for protego: filename=Protego-0.1.16-py3-none-any.whl size=7765 sha256=b3d3fb9991ec8c186883586e73e68b245bc7391cfe8733d3907c070c327e4a24\n",
      "  Stored in directory: /Users/Gustavo-NB/Library/Caches/pip/wheels/91/64/36/bd0d11306cb22a78c7f53d603c7eb74ebb6c211703bc40b686\n",
      "  Building wheel for cryptography (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cryptography: filename=cryptography-3.3.1-cp38-cp38-macosx_11_0_x86_64.whl size=412724 sha256=08ee5f9fd241e68318962557afad008f9411e94b93905da3353d739ce4511b6d\n",
      "  Stored in directory: /Users/Gustavo-NB/Library/Caches/pip/wheels/9b/bd/12/c040f2df6b28138b66b0361cd218180a278b95763fc2466951\n",
      "  Building wheel for Twisted (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Twisted: filename=Twisted-20.3.0-cp38-cp38-macosx_11_0_x86_64.whl size=3050403 sha256=3384bfbac3db344dcdb21c2037fc2c4914cc002e61b8818c5c45c53f2e246587\n",
      "  Stored in directory: /Users/Gustavo-NB/Library/Caches/pip/wheels/f2/36/1b/99fe6d339e1559e421556c69ad7bc8c869145e86a756c403f4\n",
      "  Building wheel for lxml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-4.6.2-cp38-cp38-macosx_11_0_x86_64.whl size=1662833 sha256=624212f05ad6af2e363f3f7493f0d7054425d45042b4fdc764231b0e8850047c\n",
      "  Stored in directory: /Users/Gustavo-NB/Library/Caches/pip/wheels/c3/23/4f/9b994c75aeecf7753024d150b6f5d9bb19587c2aebafa158a4\n",
      "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=11515 sha256=e0d4db51129e30d8b250d4bd7d8b9f407fd6d7b301011ebeb3d167f7c70dab7a\n",
      "  Stored in directory: /Users/Gustavo-NB/Library/Caches/pip/wheels/d1/d7/61/11b5b370ee487d38b5408ecb7e0257db9107fa622412cbe2ff\n",
      "Successfully built zope.interface protego cryptography Twisted lxml PyDispatcher\n",
      "Installing collected packages: cssselect, w3lib, lxml, parsel, cryptography, pyOpenSSL, zope.interface, protego, jmespath, itemadapter, itemloaders, service-identity, constantly, incremental, Automat, hyperlink, PyHamcrest, Twisted, queuelib, PyDispatcher, scrapy\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 PyHamcrest-2.0.2 Twisted-20.3.0 constantly-15.1.0 cryptography-3.3.1 cssselect-1.1.0 hyperlink-20.0.1 incremental-17.5.0 itemadapter-0.2.0 itemloaders-1.0.4 jmespath-0.10.0 lxml-4.6.2 parsel-1.6.0 protego-0.1.16 pyOpenSSL-20.0.1 queuelib-1.5.0 scrapy-2.4.1 service-identity-18.1.0 w3lib-1.22.0 zope.interface-5.2.0\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca Scrapy: https://docs.scrapy.org/en/latest/index.html\n",
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uritools\n",
      "  Downloading uritools-3.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: uritools\n",
      "Successfully installed uritools-3.0.0\n"
     ]
    }
   ],
   "source": [
    "#biblioteca URITools: https://pypi.org/project/uritools/\n",
    "!pip install uritools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-28 18:44:52 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
      "2020-12-28 18:44:52 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Nov 20 2020, 23:57:10) - [Clang 12.0.0 (clang-1200.0.32.27)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform macOS-11.1-x86_64-i386-64bit\n",
      "2020-12-28 18:44:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2020-12-28 18:44:52 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
      " 'LOGSTATS_INTERVAL': 0}\n",
      "2020-12-28 18:44:52 [scrapy.extensions.telnet] INFO: Telnet Password: 8c8696863f0c3461\n",
      "2020-12-28 18:44:52 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage']\n",
      "2020-12-28 18:44:52 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-12-28 18:44:52 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-12-28 18:44:52 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-12-28 18:44:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-12-28 18:44:52 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-12-28 18:44:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.igti.com.br/blog/> (referer: None)\n",
      "2020-12-28 18:44:55 [asyncio] DEBUG: Using selector: KqueueSelector\n",
      "[s] Available Scrapy objects:\n",
      "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
      "[s]   crawler    <scrapy.crawler.Crawler object at 0x10efbd7c0>\n",
      "[s]   item       {}\n",
      "[s]   request    <GET https://www.igti.com.br/blog/>\n",
      "[s]   response   <200 https://www.igti.com.br/blog/>\n",
      "[s]   settings   <scrapy.settings.Settings object at 0x10efbdf40>\n",
      "[s]   spider     <DefaultSpider 'default' at 0x10f445df0>\n",
      "[s] Useful shortcuts:\n",
      "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
      "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
      "[s]   shelp()           Shell help (print this help)\n",
      "[s]   view(response)    View response in a browser\n",
      "2020-12-28 18:44:55 [asyncio] DEBUG: Using selector: KqueueSelector\n",
      "\u001b[?1l\u001b[6n\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[8D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
      "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[8D\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[0m\n",
      "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\n",
      "\u001b[?1l\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#determina URL de raspagem\n",
    "!scrapy shell https://www.igti.com.br/blog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: response.url\r\n"
     ]
    }
   ],
   "source": [
    "!response.url\n",
    "!response.headers\n",
    "!response.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unknown file attribute: i\n",
      "zsh:1: unknown file attribute: i\n",
      "zsh:1: no matches found: len(response.css(div))\n"
     ]
    }
   ],
   "source": [
    "# Recupera o elemento //title/ usando o Xpath\n",
    "!response.xpath('//title')\n",
    "\n",
    "#Recupera oe elemtno <title> com seletor CSS\n",
    "!response.css('title')\n",
    "\n",
    "#Conta o número de elementos <div>\n",
    "!len(response.css('div'))\n",
    "\n",
    "#Retorna uma instância específica\n",
    "!response.xpath('//article')[0]\n",
    "\n",
    "#Extrai a instância especificada\n",
    "!response.xpath('//article')[0].get()\n",
    "!response.xpath('//article').extract() #Retorna lista de todos elementos\n",
    "\n",
    "#busca classe específica\n",
    "!response.xpath(\"//article/div/div\").get()\n",
    "!response.xpath(\"//div[@class='entry-category']\")\n",
    "\n",
    "!categoria = response.xpath(\"//div[@class='entry-category']//a\")\n",
    "\n",
    "!for categoria in categoria:\n",
    "    txt = categoria.xpath('text()').extract()\n",
    "    link = categoria.xpath('@href').extract()\n",
    "    print(txt)\n",
    "    print(link)\n",
    "    \n",
    "!categoria = response.xpath(\"//div[@class='entry-category']//a\")[0]\n",
    "!categora.extract()\n",
    "!link = categoria.xpath('@href').extract()\n",
    "!print(link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostra o tipo de variável\n",
    "!type(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#captura a string do link\n",
    "!url = ''.join(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altera a página do boot\n",
    "fetch(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
